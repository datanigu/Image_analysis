{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network testing\n",
    "Use this notebook to fine-tune pre-trained Xception from Keras found here https://keras.io/applications/#xception\n",
    "NB: More trained models can be found here https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My own utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "from random import shuffle\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(root_dir, img_types):\n",
    "    #os.walk creates 3-tuple with (dirpath, dirnames, filenames)\n",
    "    \n",
    "    # Get all the root directories, subdirectories, and files\n",
    "    full_paths = [x for x in os.walk(root_dir)] \n",
    "    imgs_temp = [os.path.join(ds,f) for ds,_,fs in full_paths for f in fs if f]   \n",
    "    \n",
    "    # Filter out so only have directories with .jpg, .tiff, .tif, .png, .jpeg\n",
    "    imgs = [j for j in imgs_temp if any (k in j for k in img_types)]\n",
    "    return imgs\n",
    "\n",
    "def get_dimensions(files):\n",
    "    # Set starting points for min and max dimensions\n",
    "    min_height, min_width = 10000, 10000\n",
    "    max_height, max_width = 0, 0\n",
    "    \n",
    "    for f in files:\n",
    "        # Read in images\n",
    "        img = cv.imread(f) # Read in images\n",
    "        h,w = img.shape[:2] # get height and width\n",
    "        \n",
    "        # Update min and max values, if necessary\n",
    "        if h < min_height:\n",
    "            min_height = h \n",
    "        if h > max_height:\n",
    "            max_height = h\n",
    "        if w < min_width:\n",
    "            min_width = w\n",
    "        if w > max_width:\n",
    "            max_width = w\n",
    "            \n",
    "    return min_height, min_width, max_height, max_width\n",
    "\n",
    "def make_labels(files):\n",
    "    # Assume input is a list of complete file paths.\n",
    "    # Count the number of unique directory names that are immediate parent of the files.\n",
    "    # Order the directory names alphabetically from a-z, and associate labels accordingly.\n",
    "    set_temp = {x.split('/')[-2] for x in files} #doing as set to get only unique values\n",
    "    list_temp = list(set_temp) #Change to list so can interate over it\n",
    "    list_new = sorted(list_temp) #Alphabetizing\n",
    "    label_dict = {list_new[x]:x for x in range(len(list_new))} #create dictionary with category:index\n",
    "    \n",
    "    return label_dict\n",
    "\n",
    "def make_train_val(files, labels):\n",
    "    train=[]\n",
    "    valid = []\n",
    "    train_labels = []\n",
    "    valid_labels = []\n",
    "    train_prop = 0.6 #proportion of data set that will be training\n",
    "    for key in labels: #going through each key\n",
    "        temp = [f for f in files if key in f] #getting all files in a specific category (ie key)\n",
    "        train.extend(temp[:math.ceil(train_prop*len(temp))]) #training data set\n",
    "        valid.extend(temp[math.ceil(train_prop*len(temp)):]) # validation data set\n",
    "    train_labels = [x.split('/')[-2] for x in train]\n",
    "    valid_labels = [x.split('/')[-2] for x in valid]\n",
    "    return train, valid, train_labels, valid_labels\n",
    "\n",
    "def make_train_val_test(files, labels):\n",
    "    train=[]\n",
    "    valid = []\n",
    "    test =[]\n",
    "    train_labels = []\n",
    "    valid_labels = []\n",
    "    test_labels = []\n",
    "    train_prop = 0.6 #proportion of data set that will be training\n",
    "    val_prop = 0.2 #proprotion of dataset that is validation\n",
    "    for key in labels: #going through each key\n",
    "        temp = [f for f in files if key in f] #getting all files in a specific category (ie key)\n",
    "        lower_prop = math.ceil(train_prop*len(temp))\n",
    "        train.extend(temp[:lower_prop]) #training data set\n",
    "        valid.extend(temp[lower_prop:lower_prop+math.ceil(val_prop*len(temp))]) # validation data set\n",
    "        test.extend(temp[lower_prop+math.ceil(val_prop*len(temp)):])\n",
    "    train_labels = [x.split('/')[-2] for x in train]\n",
    "    valid_labels = [x.split('/')[-2] for x in valid]\n",
    "    test_labels =  [x.split('/')[-2] for x in test]\n",
    "    return train, valid, test, train_labels, valid_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(files, label_map, batch_size, resize_size, num_color_channels, augment=False, predict=False):\n",
    "    shuffle(files)\n",
    "    count = 0\n",
    "    num_files = len(files)\n",
    "    num_classes = len(label_map)\n",
    "    \n",
    "    batch_out = np.zeros((batch_size, resize_size[0], resize_size[1], num_color_channels), dtype=np.uint8)\n",
    "    labels_out = np.zeros((batch_size,num_classes)) #one-hot labeling, which is why have num_classes num of col.   \n",
    "\n",
    "    while True: # while True is to ensure when yielding that start here and not previous lines\n",
    "\n",
    "        f = files[count]\n",
    "        img = cv.imread(f)       \n",
    "\n",
    "        # Resize\n",
    "        # First resize while keeping aspect ratio\n",
    "        rows,cols = img.shape[:2] # Define in input num_color_channels in case want black and white\n",
    "        rc_ratio = rows/cols\n",
    "        if resize_size[0] > int(resize_size[1]*rc_ratio):# if resize rows > rows with given aspect ratio\n",
    "            img = cv.resize(img, (resize_size[1], int(resize_size[1]*rc_ratio)))#NB: resize dim arg are col,row\n",
    "        else:\n",
    "            img = cv.resize(img, (int(resize_size[0]/rc_ratio), resize_size[0]))\n",
    "            \n",
    "        # Second, pad to final size\n",
    "        rows,cols = img.shape[:2] #find new num rows and col of resized image\n",
    "        res = np.zeros((resize_size[0], resize_size[1], num_color_channels), dtype=np.uint8)#array of zeros\n",
    "        res[(resize_size[0]-rows)//2:(resize_size[0]-rows)//2+rows,\n",
    "            (resize_size[1]-cols)//2:(resize_size[1]-cols)//2+cols,:] = img # fill in image in middle of zeros\n",
    "                \n",
    "        # Augmentation \n",
    "        if augment:            \n",
    "            rows,cols = res.shape[:2]\n",
    "            # calculates affine rotation with random angle rotation, keeping same center and scale\n",
    "            M = cv.getRotationMatrix2D((cols/2,rows/2),np.random.uniform(0.0,360.0,1),1) \n",
    "            # applies affine rotation\n",
    "            res = cv.warpAffine(res,M,(cols,rows))\n",
    "\n",
    "        # Change to gray scale if input argument num_color_channels = 1\n",
    "        if num_color_channels == 1: \n",
    "            res = cv.cvtColor(res, cv.COLOR_BGR2GRAY)# convert from bgr to gray\n",
    "            res = res[...,None] # add extra dimension with blank values to very end, needed for keras\n",
    "            \n",
    "        batch_out[count%batch_size,...] = res # put image in position in batch, never to exceed size of batch\n",
    "        \n",
    "        for k in label_map.keys():\n",
    "            if k in f: #if a category name is found in the path to the file of the image\n",
    "                labels_out[count%batch_size,:] = np_utils.to_categorical(label_map[k],num_classes) #one hot labeling\n",
    "                break   \n",
    "                \n",
    "        count += 1\n",
    "        if count == num_files:# if gone through all files, restart the counter\n",
    "            count = 0\n",
    "        if count%batch_size == 0: #if gone through enough files to make a full batch\n",
    "            if predict: # i.e., there is no label for this batch of images, so in prediction mode\n",
    "                yield batch_out.astype(np.float)/255.\n",
    "            else: # training\n",
    "                yield batch_out.astype(np.float)/255., labels_out\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files is  1679\n",
      "example file names are  ['/Users/dtaniguchi/Research/Image_classification/Scripps_plankton_camera_system_images/Labeled_ciliates_and_other/Ciliate/SPCP2-1551916275-018743-003-12-304-120-104.jpg', '/Users/dtaniguchi/Research/Image_classification/Scripps_plankton_camera_system_images/Labeled_ciliates_and_other/Ciliate/SPCP2-1549460119-039576-001-664-1800-96-104.jpg', '/Users/dtaniguchi/Research/Image_classification/Scripps_plankton_camera_system_images/Labeled_ciliates_and_other/Ciliate/SPCP2-1564409932-302705-002-192-932-104-96.jpg', '/Users/dtaniguchi/Research/Image_classification/Scripps_plankton_camera_system_images/Labeled_ciliates_and_other/Ciliate/SPCP2-1564466851-138834-002-792-708-136-144.jpg']\n",
      "Over all images - minimum height: 24, minimum width: 32, maximum height: 312, maximum width:448\n",
      "{'Ciliate': 0, 'Other': 1}\n",
      "1008\n",
      "671\n",
      "train labels length is  1008\n",
      "validation labels length is 671\n"
     ]
    }
   ],
   "source": [
    "# Get full paths to all classification data\n",
    "# Data is assumed to reside under the directory \"root_dir\", and data for each class is assumed to reside in a separate subfolder\n",
    "# root_dir = '/Users/dtaniguchi/Research/Image_classification/Scripps_plankton_camera_system_images/Practice_images'\n",
    "root_dir = '/Users/dtaniguchi/Research/Image_classification/Scripps_plankton_camera_system_images/Labeled_ciliates_and_other'\n",
    "\n",
    "\n",
    "img_types=['.jpg', '.tiff', '.tif', '.png', '.jpeg']\n",
    "\n",
    "files = get_image_files(root_dir, img_types)\n",
    "print('number of files is ',len(files))\n",
    "print('example file names are ', files[0:4])\n",
    "\n",
    "# Get the dimension range of the data for informational purposes\n",
    "minh,minw,maxh,maxw = get_dimensions(files)\n",
    "print('Over all images - minimum height: {}, minimum width: {}, maximum height: {}, maximum width:{}'.format(minh,minw,maxh,maxw))\n",
    "\n",
    "# Assign numerical labels to categories - the number of categories is equal to the number of subfolders\n",
    "label_map = make_labels(files)\n",
    "print(label_map)\n",
    "\n",
    "# Split the data into training and validation\n",
    "train_files, val_files, train_labels, val_labels = make_train_val(files, label_map)\n",
    "print(len(train_files))\n",
    "print(len(val_files))\n",
    "\n",
    "print('train labels length is ',len(train_labels))\n",
    "print('validation labels length is', len(val_labels))\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning\n",
    "The code below was taken from https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes and must be adapted for use with xception instead of InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running InceptionV3 just to see if I can get it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3#--[don't need if running Xception]\n",
    "#from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#input_shape taken from get_dimensions in Jupyter notebook Image_classification\n",
    "# create the base pre-trained model\n",
    "\n",
    "#base_model = Xception(include_top=False, weights='imagenet', input_tensor=None, input_shape=(880,920,3), pooling=None)\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False) #--[don't need if using Xception]\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# and a logistic layer -- let's say we have x classes--determined by len(label_map)\n",
    "predictions = Dense(len(label_map), activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 32\n",
    "batch_gen = get_batches(train_files,label_map,batch_size=BS,resize_size=[224, 224],num_color_channels=3)\n",
    "val_gen = get_batches(val_files,label_map,batch_size=BS,resize_size=[224, 224],num_color_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n"
     ]
    }
   ],
   "source": [
    "# Code in this cell taken from \n",
    "#https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "# train the model on the new data for a few epochs\n",
    "# initialize the number of epochs and batch size\n",
    "EPOCHS = 1000\n",
    "BS = 32\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "# aug = ImageDataGenerator(rotation_range=180, zoom_range=0.15,\n",
    "#     width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "#     horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# train the network\n",
    "# H = model.fit_generator(aug.flow(train_files, train_labels, batch_size=BS),\n",
    "#         validation_data=(val_files, val_labels), steps_per_epoch=len(train_files) // BS,epochs=EPOCHS)\n",
    "\n",
    "\n",
    "# class PlotCallbacks(keras.Callback):\n",
    "#     def on_epoch_end(self, batch, logs={}):\n",
    "#         print(logs)\n",
    "#         return\n",
    "\n",
    "\n",
    "model.fit_generator(batch_gen,validation_data=val_gen,validation_steps =4, steps_per_epoch=len(train_files) // BS,epochs=EPOCHS,\n",
    "                   workers=1, use_multiprocessing=False, verbose =2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True \n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "\n",
    "model.fit_generator(batch_gen,validation_data=val_gen,validation_steps =4, steps_per_epoch=len(train_files) // BS,epochs=EPOCHS,\n",
    "                   workers=1, use_multiprocessing=False, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO predict using test data, not validation data\n",
    "predict_gen = get_batches(val_files,label_map,batch_size=1,resize_size=[224, 224],num_color_channels=3)\n",
    "prediction = model.predict_generator(predict_gen,steps = len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_class(prediction,label_map):\n",
    "    predict_max = np.argmax(prediction,axis=1)#provides index of max value out of prediction classes\n",
    "    predict_label = []\n",
    "    for i in range(len(predict_max)):\n",
    "        for k,v in label_map.items():\n",
    "                if predict_max[i] == v:\n",
    "                    predict_label.append(k)\n",
    "    return predict_label    \n",
    "\n",
    "def prop_correct(predict_label,actual_label):\n",
    "    correct_class = []\n",
    "    for i in range(len(predict_label)):\n",
    "        if predict_label[i]==actual_label[i]:\n",
    "            correct_class.append(1)\n",
    "        else:\n",
    "            correct_class.append(0)\n",
    "    num_correct = sum(correct_class)\n",
    "    proportion_correct = num_correct/len(predict_label)\n",
    "    return proportion_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction\n",
    "print(label_map)\n",
    "print(prediction[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class = convert_to_class(prediction,label_map)\n",
    "print(predict_class[0:5])\n",
    "print(prop_correct(predict_class,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = []\n",
    "predict_max = np.argmax(prediction,axis=1)#provides index of max value out of prediction classes\n",
    "\n",
    "for i in range(len(predict_max)):\n",
    "    for k,v in label_map.items():\n",
    "            if predict_max[i] == v:\n",
    "                testing.append(k)\n",
    "                \n",
    "list_comp = [k for x in predict_max for k,v in label_map.items() if predict_max[x]==v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction[0:6])\n",
    "print(predict_max[0:6])\n",
    "print(testing[0:6])\n",
    "\n",
    "\n",
    "print(list_comp[0:6])\n",
    "print(label_map)\n",
    "dododo = convert_to_class(prediction,label_map)\n",
    "print(dododo[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
